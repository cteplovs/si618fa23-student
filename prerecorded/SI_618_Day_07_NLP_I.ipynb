{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond regex: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "# Why learn NLP?\n",
    "- Natural language = human language\n",
    "- We use language to learn about the world\n",
    "- How machines understand human langauge?\n",
    "- How can we quantify the meaning of language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications?\n",
    "- Probabily any service that uses text as information\n",
    "- Search engine, SNS\n",
    "    - What's the document about?\n",
    "    - How do you determine the similarity?\n",
    "- Virtual assistants: Alexa, Google Assistant, Cortana, etc. \n",
    "    - Understand the semantic information from your speech from parsed text\n",
    "- Biology, genetics\n",
    "    - Genetic information / DNA sequence as text\n",
    "    - Draw networks of proteins/molecules from vast amount of scientific papers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://github.com/umsi-data-science/si370/raw/master/resources/nlp/Slide27.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Fast, and extensible NLP package for Python\n",
    "- <https://spacy.io/>\n",
    "- NOTE: You will need to install this, and then (one time only as well) download the English corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment *one* of the following lines \n",
    "#!pip install spacy\n",
    "#!conda install -y spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the following line ONCE only\n",
    "#! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# loading up the language model: English\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 0. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from Project Gutenberg: Grimms' Fairy Tales\n",
    "sentences = \"\"\"\n",
    "As soon as the time came when he was to declare the secret, he was taken\n",
    "before the king with the three branches and the golden cup; and the\n",
    "twelve princesses stood listening behind the door to hear what he would\n",
    "say. And when the king asked him. ‘Where do my twelve daughters dance at\n",
    "night?’ he answered, ‘With twelve princes in a castle under ground.’ And\n",
    "then he told the king all that had happened, and showed him the three\n",
    "branches and the golden cup which he had brought with him. Then the king\n",
    "called for the princesses, and asked them whether what the soldier said\n",
    "was true: and when they saw that they were discovered, and that it was\n",
    "of no use to deny what had happened, they confessed it all. And the king\n",
    "asked the soldier which of them he would choose for his wife; and he\n",
    "answered, ‘I am not very young, so I will have the eldest.’--And they\n",
    "were married that very day, and the soldier was chosen to be the king’s\n",
    "heir.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Section goal: calculate the frequency of each word\n",
    "- See which words are more frequent.\n",
    "- Generate more meaningful summary for the above paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 0-1. lowering the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sent_low = sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sent_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## 0-2. remove punctuation and special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exclude special characters one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~‘’''' # list of special characters you want to exclude\n",
    "sent_low_pnct = \"\"\n",
    "for char in sent_low:\n",
    "    if char not in punctuations:\n",
    "        sent_low_pnct = sent_low_pnct + char\n",
    "\n",
    "sent_low_pnct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Alternatively, we can use regular expression to remove punctuations\n",
    "- So we don't have to list up all possible special characters that we want to remove\n",
    "- https://docs.python.org/3.4/library/re.html\n",
    "- https://en.wikipedia.org/wiki/Regular_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "sent_low_pnct2 = re.sub(r'[^\\w\\s]', ' ', sent_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sent_low_pnct2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- However, special character ```\\n``` (linebreak) still exists in both cases. Let's remove these additionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.linesep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sent_low_pnct = sent_low_pnct.replace(os.linesep, \" \")\n",
    "sent_low_pnct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### So... at least 3 possible ways to replace characters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 0-3. Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Stop words usually refers to the most common words in a language\n",
    "    - No single universal stopwords\n",
    "    - Often stopwords are removed to improve the performance of NLP models\n",
    "    - https://en.wikipedia.org/wiki/Stop_words\n",
    "    - https://en.wikipedia.org/wiki/Most_common_words_in_English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Import the list of stop words from ```spaCy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Goal: We are going to count the frequency of each word from the paragraph, to see which words can be used to represent the paragraph's content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we do not remove stopwords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that our paragraph is stored as a single string object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_low_pnct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Split the paragraph into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sent_low_pnct.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Count the words from the list\n",
    "- Words that can occur in any kind of paragraphs...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,10))\n",
    "sns.countplot(words, order=pd.Series(words).value_counts().index)\n",
    "# sns.countplot(words_nostop, order=[counted[0] for counted in Counter(words_nostop).most_common()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### When we removed stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# split sentence into words\n",
    "words_nostop = list()\n",
    "for word in words:\n",
    "    if word not in STOP_WORDS:\n",
    "        words_nostop.append(word)\n",
    "# words_nostop = [word for word in words if word not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- More comprehensible, and unique list or words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(words_nostop).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,10))\n",
    "sns.countplot(words_nostop, order=pd.Series(words_nostop).value_counts().index)\n",
    "# sns.countplot(words_nostop, order=[counted[0] for counted in Counter(words_nostop).most_common()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Extracting linguistic features from spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1-1. Tokenize\n",
    "- Token: a semantic unit for analysis\n",
    "    - (Loosely) equal term for word\n",
    "        - ```sent_low_pnct.split()```\n",
    "    - Tricky cases\n",
    "        - aren't $\\rightarrow$ ![](https://nlp.stanford.edu/IR-book/html/htmledition/img88.png) ![](https://nlp.stanford.edu/IR-book/html/htmledition/img89.png) ? ![](https://nlp.stanford.edu/IR-book/html/htmledition/img86.png) ?\n",
    "        - O'Neil $\\rightarrow$ ![](https://nlp.stanford.edu/IR-book/html/htmledition/img83.png) ? ![](https://nlp.stanford.edu/IR-book/html/htmledition/img84.png) ![](https://nlp.stanford.edu/IR-book/html/htmledition/img81.png) ?\n",
    "        - https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
    "- In ```spaCy```:\n",
    "    - Many token types, like word, puntuation symbol, whitespace, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's dissect the sentence!\n",
    "\n",
    "- initiating the ```spaCy``` object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# examples partially taken from https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Our sentence: \"Hello World!\"\n",
    "    - Pass the sentence string to the ```spaCy``` object ```nlp```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The sentence is considered as a short document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(doc), doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- As importing the sentence string above, ```spaCy``` split the sentence into tokens (tokenization!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,token in enumerate(doc):\n",
    "    print(i, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- With index information (location from the sentence) of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10| 11|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| H | e | l | l | o | _ | W | o | r | l | d | ! |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i, token in enumerate(doc):\n",
    "    print(i, token.text, token.idx) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- And many more!\n",
    "    - https://spacy.io/api/token#attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(sentences)\n",
    "\n",
    "print(\"text\\tidx\\tlemma\\tlower\\tpunct\\tspace\\tshape\\tPOS\")\n",
    "for token in doc:\n",
    "    if token.is_space:\n",
    "        print(\"SPACE\")\n",
    "    else:\n",
    "        print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "            token.text,\n",
    "            token.idx,\n",
    "            token.lemma_,\n",
    "            token.lower_,\n",
    "            token.is_punct,\n",
    "            token.is_space,\n",
    "            token.shape_,\n",
    "            token.pos_\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-2. Sentence detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- For the document with multiple sentences, we would need to separate  each sentence.\n",
    "- In ```spaCy```, the job is more convenient (and would cause less mistakes) than using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# same document, but initiate as the spaCy object...\n",
    "doc = nlp(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Sentences are stored as a generator object\n",
    "    - Instead of storing sentences as a list, each sentence is stored as a item in the generator object \n",
    "    - Iteratable (i.e., can be used in a for loop)\n",
    "    - More efficient memory use\n",
    "    - https://wiki.python.org/moin/Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Printing sentences with the index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-3. POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I want to find words with particular part-of-speech!\n",
    "- Different part-of-speech words carry different information\n",
    "    - e.g., noun (subject), verb (action term), adjective (quality of the object) \n",
    "- https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Yelp review!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.yelp.com/biz/ajishin-novi?hrid=juA4Zn2TX7845vNFn4syBQ&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)\n",
    "doc = nlp(\"\"\"One of the best Japanese restaurants in Novi. Simple food, great taste, amazingly price. I visit this place a least twice month.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- multiple sentences exist in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Question: which words are adjective (ADJ)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(doc.sents):\n",
    "    print(\"__sentence__:\", i)\n",
    "    print(\"_token_ \\t _POS_\")\n",
    "    for token in sent:\n",
    "        print(token.text, \"\\t\", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Democrat Stacey Abrams was trailing in her bid to become the nation’s first female African-American governor, but her campaign said voting problems as well as uncounted absentee and provisional ballots could force a runoff.\"\"\")\n",
    "\n",
    "print([(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(\"__sentence__:\", i)\n",
    "    print(\"_token_ \\t _POS_\")\n",
    "    for token in sent:\n",
    "        print(token.text, \"\\t\", token.pos_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url='https://www.nytimes.com/2018/11/07/us/politics/democrats-republicans-house.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "def url_to_string(url):\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    for script in soup([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
    "ny_bb = url_to_string(url)\n",
    "article = nlp(ny_bb)\n",
    "len(article.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "labels = [x.label_ for x in article.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,10))\n",
    "sns.countplot(labels, order=pd.Series(labels).value_counts().index)\n",
    "# sns.countplot(words_nostop, order=[counted[0] for counted in Counter(words_nostop).most_common()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-4. Gramatical dependency\n",
    "- Words are gramatically related in a sentence.\n",
    "- Conveys much semantic information about the sentential context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "spacy.displacy.render(article, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
